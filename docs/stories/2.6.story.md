# Story 2.6: 实时市场数据集成与高级过滤器

## Status
Done

## Story
**As a** 系统，
**I want** 集成akshare获取实时A股市场数据（市值、成交量），并实现基于相关性和市场指标的高级评分过滤器，
**so that** 能够根据实际市场数据筛选和排序相关公司，为用户提供更精准的投资参考。

## Acceptance Criteria
1. 系统能够通过akshare API获取所有A股公司的最新一天市值数据。
2. 系统能够通过akshare API获取所有A股公司最近5个交易日的成交量数据。
3. 市场数据被正确存储并定期更新（每日更新）。
4. 实现新的评分算法：L = X * (S + V)，其中：
   - X为相关系数（高相关=1，中相关=0.5）
   - S为市值评分（60-85亿=1，40-60亿=2，<40亿=3）
   - V为成交量评分（1-2亿=1，0.5-1亿=2，<0.5亿=3）
5. 只返回市值低于85亿且5日平均成交量低于2亿的公司。
6. 结果按照L值降序排序。
7. API响应的metadata中准确反映实际应用的过滤器。

## Tasks / Subtasks

- [x] Task 1: 创建akshare市场数据适配器 (AC: 1, 2)
  - [x] 在`src/infrastructure/`中创建`market_data/`目录
  - [x] 创建`akshare_adapter.py`实现AkshareMarketDataAdapter类
  - [x] 实现`get_all_market_snapshot()`方法，合并沪深和北交所数据
  - [x] 使用`ak.stock_zh_a_spot_em()`获取沪深A股数据
  - [x] 使用`ak.stock_bj_a_spot_em()`获取北交所数据
  - [x] 提取关键字段：代码、名称、总市值、流通市值、成交额
  - [x] 添加异常处理和重试机制
  - [x] 添加数据验证确保返回数据格式正确

- [x] Task 2: 实现市场数据存储与缓存 (AC: 3)
  - [x] 创建数据库迁移脚本添加`market_data_daily`表和`market_data_current`视图
  - [x] 在`src/infrastructure/persistence/postgres/`创建`market_data_repository.py`
  - [x] 实现`save_daily_snapshot()`方法批量插入每日数据
  - [x] 实现`get_market_data_with_5day_avg()`方法使用视图查询
  - [x] 使用PostgreSQL的`INSERT ON CONFLICT`处理重复数据
  - [x] 实现数据清理策略（保留最近N天数据）
  - [x] 添加Redis缓存层缓存当日查询结果

- [x] Task 3: 实现市场数据同步服务 (AC: 3)
  - [x] 在`src/domain/services/`创建`market_data_sync_service.py`
  - [x] 实现`sync_daily_market_data()`方法协调适配器和仓储
  - [x] 添加交易日判断逻辑（跳过周末和节假日）
  - [x] 实现同步状态监控和日志记录
  - [x] 添加同步失败的重试机制（最多3次）
  - [x] 记录同步历史和性能指标

- [x] Task 4: 更新市场过滤器实现高级评分 (AC: 4, 5, 6)
  - [x] 创建`src/shared/config/market_filter_config.py`配置文件
  - [x] 定义可配置的评分规则类（MarketFilterConfig）
  - [x] 修改`src/domain/services/market_filter.py`
  - [x] 从AggregatedCompany获取relevance_score作为X值
  - [x] 实现基于配置的市值分档评分逻辑
  - [x] 实现基于配置的成交量分档评分逻辑
  - [x] 实现L = X * (S + V)评分公式
  - [x] 添加基于配置的过滤条件
  - [x] 实现按L值降序排序，返回包含L值的结果

- [x] Task 5: 更新搜索用例集成新评分系统 (AC: 6, 7)
  - [x] 修改`src/application/use_cases/search_similar_companies.py`
  - [x] 确保市场过滤在公司聚合之后执行（保持现有流程）
  - [x] 将AggregatedCompany列表传递给市场过滤服务
  - [x] 市场过滤服务返回包含L值的筛选后结果
  - [x] 确保metadata正确记录应用的过滤器和实际参数值
  - [x] 保持与现有API契约的兼容性

- [x] Task 6: 创建数据初始化和定时任务脚本 (AC: 1, 2, 3)
  - [x] 在`scripts/`创建`init_market_data.py`初始化脚本
  - [x] 实现首次全量数据拉取（获取最近5个交易日数据）
  - [x] 在`scripts/`创建`sync_market_data_daily.py`日常同步脚本
  - [x] 添加进度显示和错误处理
  - [x] 实现交易日判断（跳过非交易日）
  - [x] 支持手动运行和cron定时任务

- [x] Task 7: 编写单元测试 (Testing Requirements)
  - [x] 在`tests/unit/infrastructure/market_data/`创建测试
  - [x] 测试akshare适配器的各个方法
  - [x] 测试市场数据仓储的CRUD操作
  - [x] 测试高级评分算法的正确性
  - [x] 测试边界情况（无数据、部分数据、异常值）

- [x] Task 8: 编写集成测试 (Testing Requirements)
  - [x] 在`tests/integration/`创建市场数据集成测试
  - [x] 测试完整的数据同步流程
  - [x] 测试过滤和评分的端到端流程
  - [x] 验证API响应包含正确的过滤器元数据

## Dev Notes

### Previous Story Insights
Story 2.5实现了基础的市场过滤框架，但使用的是存根实现。关键的MarketDataRepository接口已定义，现在需要用真实的akshare集成替换存根实现。过滤器的基础架构（graceful degradation、metadata tracking）已经就绪。
[Source: Story 2.5 Dev Agent Record]

### Current Scoring System Context
当前系统的相关性评分机制：
1. **向量搜索阶段**：使用pgvector计算embedding的余弦相似度，得到`similarity_score`
2. **Rerank阶段**（可选）：使用Qwen Rerank模型重新评分，得到`rerank_score`
3. **最终评分计算**：`final_score = 0.7 * rerank_score + 0.3 * importance_score`
4. **公司聚合**：按公司分组后，取所有概念的最高分作为`relevance_score`

对于市场过滤器的X值，应直接使用AggregatedCompany的`relevance_score`，这是一个0-1的连续值，已经综合了向量相似度、重排序分数和业务重要性。不需要人为设定高/中/低的阈值映射。
[Source: Code investigation of similarity_calculator.py, company_aggregator.py]

### Processing Flow
完整的处理流程顺序：
1. **向量搜索** (Story 2.2) → 获取相似business concepts
2. **Rerank精排** (Story 2.3) → 使用Qwen模型重新评分
3. **核心排序** (Story 2.4) → 应用加权公式：w1*rerank + w2*importance
4. **公司聚合** (Story 2.5) → 按公司分组，取最高分作为relevance_score
5. **市场过滤** (Story 2.6) → 应用市场数据过滤和L值评分
6. **最终输出** → 返回过滤后的公司列表，按L值排序

市场过滤是最后一步，在所有相关性计算和聚合完成后执行。

### Market Data Schema
需要创建新的数据库表存储每日市场数据快照：
```sql
-- Daily snapshot table for efficient 5-day average calculation
CREATE TABLE market_data_daily (
    company_code VARCHAR(10),
    trading_date DATE,
    total_market_cap DECIMAL(20, 2),      -- 总市值
    circulating_market_cap DECIMAL(20, 2), -- 流通市值
    turnover_amount DECIMAL(20, 2),        -- 成交额 (volume in CNY)
    created_at TIMESTAMPTZ DEFAULT NOW(),
    PRIMARY KEY (company_code, trading_date),
    FOREIGN KEY (company_code) REFERENCES companies(company_code)
);

CREATE INDEX idx_daily_date ON market_data_daily(trading_date);
CREATE INDEX idx_daily_cap ON market_data_daily(total_market_cap);
CREATE INDEX idx_daily_turnover ON market_data_daily(turnover_amount);

-- View for current market data with 5-day average
CREATE VIEW market_data_current AS
SELECT 
    m1.company_code,
    m1.total_market_cap as current_market_cap,
    m1.turnover_amount as today_volume,
    AVG(m2.turnover_amount) as avg_5day_volume,
    m1.trading_date as last_updated
FROM market_data_daily m1
LEFT JOIN market_data_daily m2 
    ON m1.company_code = m2.company_code
    AND m2.trading_date > m1.trading_date - INTERVAL '7 days'
    AND m2.trading_date < m1.trading_date
WHERE m1.trading_date = (SELECT MAX(trading_date) FROM market_data_daily)
GROUP BY m1.company_code, m1.total_market_cap, m1.turnover_amount, m1.trading_date;
```
[Source: architecture/3-数据库详细设计.md]

### Akshare Integration Details (Optimized Approach)
基于研究，最优的数据获取策略是使用每日快照方式：

**核心API函数**：
- `ak.stock_zh_a_spot_em()`: 获取沪深A股实时行情数据（~5000只股票）
- `ak.stock_bj_a_spot_em()`: 获取北交所实时行情数据（~200只股票）

**返回的关键字段**：
- `代码`: 股票代码
- `名称`: 股票名称
- `总市值`: Total market cap
- `流通市值`: Circulating market cap
- `成交额`: Turnover amount in CNY (当日成交额)

**优化策略**：
1. **每日一次调用**：在收盘后运行一次，获取所有股票数据
2. **存储快照**：将每日数据存入`market_data_daily`表
3. **计算5日均值**：通过SQL查询历史快照计算，无需额外API调用
4. **性能优势**：
   - API调用：2次/天 vs 5000+次
   - 5日均值计算：毫秒级SQL查询
   - 历史数据保留用于分析

**实现示例**：
```python
def collect_daily_market_snapshot():
    # Get all A-shares including 北交所
    sh_sz_df = ak.stock_zh_a_spot_em()
    bj_df = ak.stock_bj_a_spot_em()
    all_stocks = pd.concat([sh_sz_df, bj_df], ignore_index=True)
    
    # Extract required columns
    snapshot = all_stocks[['代码', '名称', '总市值', '流通市值', '成交额']].copy()
    snapshot['trading_date'] = datetime.now().date()
    
    # Rename columns to match database schema
    snapshot.rename(columns={
        '代码': 'company_code',
        '总市值': 'total_market_cap',
        '流通市值': 'circulating_market_cap',
        '成交额': 'turnover_amount'
    }, inplace=True)
    
    return snapshot
```
[Source: External - akshare testing and optimization research]

### Advanced Scoring Algorithm
新的评分系统采用可配置的规则：

1. **相关性系数 (X)**：
   - 直接使用聚合后的`relevance_score`（0-1范围）
   - 这个分数来自于：
     - 如果有Reranker：`w1 * rerank_score + w2 * importance_score`（权重可配置）
     - 如果无Reranker：`importance_score`（向量相似度）
   - 保持连续值以反映真实相关性

2. **市值评分 (S)** - 可配置的分档规则：
   ```python
   market_cap_tiers = [
       {"min": 60e8, "max": 85e8, "score": 1},  # 60-85亿
       {"min": 40e8, "max": 60e8, "score": 2},  # 40-60亿
       {"min": 0, "max": 40e8, "score": 3}      # <40亿
   ]
   ```

3. **成交量评分 (V)** - 可配置的分档规则：
   ```python
   volume_tiers = [
       {"min": 1e8, "max": 2e8, "score": 1},    # 1-2亿
       {"min": 0.5e8, "max": 1e8, "score": 2},  # 0.5-1亿
       {"min": 0, "max": 0.5e8, "score": 3}     # <0.5亿
   ]
   ```

4. **过滤条件** - 可配置的阈值：
   ```python
   filter_config = {
       "max_market_cap": 85e8,      # 最大市值阈值
       "max_avg_volume_5d": 2e8,    # 最大5日均量阈值
   }
   ```

5. **最终得分**：L = X * (S + V)
   - 配置存储在`src/shared/config/market_filter_config.py`
   - 支持通过环境变量覆盖默认值
   - 所有阈值和分档规则可在不修改代码的情况下调整

### Configuration Design
市场过滤器配置设计示例：
```python
# src/shared/config/market_filter_config.py
from pydantic import BaseModel, Field
from typing import List

class TierConfig(BaseModel):
    """分档配置"""
    min_value: float = Field(..., description="最小值（含）")
    max_value: float = Field(..., description="最大值（不含）")
    score: float = Field(..., description="该档位的评分")
    label: str = Field(..., description="档位描述")

class MarketFilterConfig(BaseModel):
    """市场过滤器配置"""
    # 过滤阈值
    max_market_cap: float = Field(default=85e8, description="最大市值阈值")
    max_avg_volume_5d: float = Field(default=2e8, description="最大5日均量阈值")
    
    # 市值分档配置
    market_cap_tiers: List[TierConfig] = Field(
        default=[
            TierConfig(min_value=60e8, max_value=85e8, score=1.0, label="优质中盘"),
            TierConfig(min_value=40e8, max_value=60e8, score=2.0, label="标准中盘"),
            TierConfig(min_value=0, max_value=40e8, score=3.0, label="小盘股")
        ]
    )
    
    # 成交量分档配置
    volume_tiers: List[TierConfig] = Field(
        default=[
            TierConfig(min_value=1e8, max_value=2e8, score=1.0, label="高流动性"),
            TierConfig(min_value=0.5e8, max_value=1e8, score=2.0, label="中流动性"),
            TierConfig(min_value=0, max_value=0.5e8, score=3.0, label="低流动性")
        ]
    )
    
    # 相关性映射配置（如果需要离散化）
    relevance_mapping_enabled: bool = Field(
        default=False, 
        description="是否启用相关性离散映射"
    )
    relevance_tiers: List[TierConfig] = Field(
        default=[
            TierConfig(min_value=0.8, max_value=1.0, score=1.0, label="高相关"),
            TierConfig(min_value=0.5, max_value=0.8, score=0.5, label="中相关"),
            TierConfig(min_value=0, max_value=0.5, score=0.1, label="低相关")
        ],
        description="相关性映射规则（仅当relevance_mapping_enabled=True时生效）"
    )

# 环境变量覆盖示例：
# MARKET_FILTER_MAX_MARKET_CAP=100e8
# MARKET_FILTER_MAX_AVG_VOLUME_5D=3e8
```

### File Locations
- 市场过滤器配置：`src/shared/config/market_filter_config.py`
- 市场数据适配器：`src/infrastructure/market_data/akshare_adapter.py`
- 市场数据仓储：`src/infrastructure/persistence/postgres/market_data_repository.py`
- 同步服务：`src/domain/services/market_data_sync_service.py`
- 更新的过滤器：`src/domain/services/market_filter.py`
- 数据库迁移：`scripts/migration/005_add_market_data_table.sql`
- 初始化脚本：`scripts/init_market_data.py`
[Source: architecture/4-源代码目录结构-source-tree.md]

### Technical Constraints
- Python 3.13兼容性（akshare支持）
- 使用asyncio进行异步数据获取以提高性能
- 遵循项目的Pydantic 2.0模型定义标准
- 使用项目标准的日志记录策略
- 确保所有外部API调用有合适的超时和重试机制
[Source: architecture/2-技术栈.md, architecture/9-编码标准与规范.md]

### Performance Considerations
- 批量获取市场数据以减少API调用次数
- 使用Redis缓存热点数据（TTL: 1小时）
- 数据库批量插入使用PostgreSQL的COPY或INSERT ON CONFLICT
- 考虑使用连接池管理数据库连接
[Source: architecture/2-技术栈.md#Redis缓存]

### Error Handling
- akshare API调用失败：记录错误，使用上次成功获取的数据
- 部分数据缺失：标记缺失数据，继续处理可用数据
- 数据格式异常：验证并记录异常数据，跳过该条记录
- 同步失败：发送告警，保留历史数据可用性
[Source: architecture/7-错误处理与日志记录策略.md]

## Testing

### Testing Standards
- **测试文件位置**：
  - 单元测试：`tests/unit/infrastructure/market_data/`，`tests/unit/domain/services/`
  - 集成测试：`tests/integration/`
- **测试框架**：pytest >= 8.3.0
- **测试要求**：
  - 使用pytest fixtures模拟akshare响应
  - 测试各种市场条件下的评分算法
  - 模拟API失败和数据异常情况
  - 使用pytest.mark.asyncio测试异步代码
  - 确保缓存逻辑的正确性
[Source: architecture/8-测试策略.md]

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-07-23 | 1.0 | Initial story creation for akshare market data integration | Bob (Scrum Master) |
| 2025-07-23 | 2.0 | Updated with optimized daily snapshot approach based on akshare research | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
Claude Opus 4 (claude-opus-4-20250514)

### Debug Log References

### Completion Notes List
- Successfully implemented akshare market data integration with daily snapshot approach
- Created comprehensive market data storage with 5-day average calculation via SQL view
- Implemented advanced scoring algorithm L = X * (S + V) with configurable tiers
- Added graceful degradation when market data unavailable
- Created initialization and daily sync scripts with cron support
- Comprehensive test coverage including unit and integration tests
- Market filter properly integrated into search use case maintaining API compatibility
- Added Redis caching support for performance optimization

### File List
- src/infrastructure/market_data/__init__.py (new)
- src/infrastructure/market_data/akshare_adapter.py (new)
- scripts/migration/005_add_market_data_table.sql (new)
- src/infrastructure/persistence/postgres/market_data_repository.py (new)
- src/domain/services/market_data_sync_service.py (new)
- src/shared/config/market_filter_config.py (new)
- src/domain/services/market_filter.py (modified)
- src/infrastructure/persistence/postgres/market_data_repository_adapter.py (new)
- src/application/use_cases/search_similar_companies.py (modified)
- scripts/init_market_data.py (new)
- scripts/sync_market_data_daily.py (new)
- .gitignore (modified)
- tests/unit/infrastructure/market_data/__init__.py (new)
- tests/unit/infrastructure/market_data/test_akshare_adapter.py (new)
- tests/unit/domain/services/test_market_filter.py (new)
- tests/integration/test_market_data_sync_integration.py (new)
- tests/integration/test_search_api_market_filter_integration.py (new)

## QA Results

### Review Date: 2025-07-24
### Reviewed By: Quinn (Senior Developer QA)

### Code Quality Assessment
The implementation demonstrates excellent architecture and design patterns with proper separation of concerns. The market data integration is well-structured using the adapter pattern, with comprehensive error handling and graceful degradation. The advanced scoring algorithm L = X * (S + V) is correctly implemented with configurable tiers. The code follows domain-driven design principles and maintains good cohesion throughout.

### Refactoring Performed
- **File**: src/infrastructure/market_data/akshare_adapter.py
  - **Change**: Fixed bare except clause on line 212
  - **Why**: Bare except clauses catch all exceptions including system exits and keyboard interrupts
  - **How**: Changed to catch specific exceptions (ValueError, TypeError, decimal.InvalidOperation) for better error handling

### Compliance Check
- Coding Standards: ✓ Code follows project standards with proper type hints and documentation
- Project Structure: ✓ Files properly organized following hexagonal architecture
- Testing Strategy: ✓ Comprehensive unit and integration tests provided
- All ACs Met: ✓ All acceptance criteria successfully implemented

### Improvements Checklist

- [x] Fixed bare except clause in akshare adapter (_safe_decimal_conversion method)
- [x] Verified scripts/init_market_data.py exists and is properly implemented
- [x] Verified scripts/sync_market_data_daily.py exists with cron support
- [ ] Update sync_market_data_daily.py to use consistent env var names (uses DB_* instead of POSTGRES_*)
- [ ] Consider adding retry logic to init_market_data.py for historical data fetching
- [ ] Add data validation for extreme market values (e.g., negative or unreasonably high market caps)

### Security Review
No security vulnerabilities identified. Market data is properly validated and sanitized before storage. Database operations use parameterized queries preventing SQL injection.

### Performance Considerations
- Excellent use of batch operations for data insertion
- Good caching strategy with Redis (1-hour TTL)
- Efficient SQL view for 5-day average calculation
- Async/await properly used throughout for concurrent operations
- Sync script correctly uses redis.asyncio for async Redis operations

### Final Status
✓ Approved - Ready for Done

**Correction**: My initial review incorrectly stated the init_market_data.py and sync_market_data_daily.py scripts were missing. Upon re-verification, both scripts exist and are properly implemented with:
- Comprehensive error handling and logging
- Support for cron scheduling (sync script)
- Trading day detection using chinese_calendar
- Status tracking and monitoring capabilities
- Proper async/await implementation throughout