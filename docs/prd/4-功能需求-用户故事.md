# **4. 功能需求 (用户故事)**

## **Epic 1: 核心数据管道与存储实现**

* **史诗目标**: 搭建一个全自动化的数据处理流水线。实现从财报/研报的文本输入，到调用LLM进行结构化提取，再到最终将高质量JSON数据存入我们设计的PostgreSQL数据库的完整流程。此阶段的产出是一个“可查询的数据仓库”，为后续所有检索和分析功能提供数据地基。

---
## **详细用户故事**

### **Story 1.1: 环境与数据库初始化**
* **作为一个** 开发者，
* **我想要** 搭建起项目的基本代码结构，并初始化一个支持`pgvector`插件的PostgreSQL数据库，
* **以便** 为后续的数据存储和开发工作做好准备。

* **验收标准 (Acceptance Criteria):**
    1.  一个全新的Git代码仓库已在本地创建。
    2.  项目包含一个`docker-compose.yml`文件，执行`docker-compose up`后，能够成功启动一个带有`pgvector`扩展的PostgreSQL数据库服务。
    3.  项目中包含一个数据库迁移脚本（如使用Alembic或独立的SQL文件），执行该脚本后，能在数据库中成功创建`Companies`, `SourceDocuments`, 和 `BusinessConceptsMaster`三张表，且表结构与《架构文档》v2.0完全一致。

---
### **Story 1.2: LLM数据提取脚本实现**
* **作为一个** 开发者，
* **我想要** 创建一个基于LangChain的自动化脚本，
* **以便** 能够读取指定的财报文件，使用我们最终版的提示词调用LLM API，并将返回的JSON文本准确解析为Python数据对象。

* **验收标准:**
    1.  脚本可以接受一个本地文件路径作为输入参数。
    2.  脚本能成功读取文件内容，并正确组装我们最终版的提示词。
    3.  脚本能成功调用**Google Gemini 1.5 Pro LLM API**并获取响应。
    4.  脚本使用LangChain的`PydanticOutputParser`，能将LLM返回的JSON字符串成功验证并解析为预定义的、结构化的数据对象。
    5.  如果LLM返回的内容不符合JSON格式或验证失败，脚本能够捕获异常并记录错误日志。

---
### **Story 1.3: 原始数据归档**
* **作为一个** 系统，
* **我想要** 在从LLM成功获取并解析出结构化数据后，自动将这份原始JSON进行归档，
* **以便** 建立一个永久的、可追溯的原始数据档案，用于未来的模型再训练或问题排查。

* **验收标准:**
    1.  在Story 1.2的脚本成功执行后，`SourceDocuments`表中会新增一条对应的记录。
    2.  该记录中的`raw_llm_output`字段（JSONB类型）完整地保存了从LLM获取的、未经修改的JSON数据。
    3.  记录中的`company_code`, `doc_type`, `doc_date`等元信息被正确填充。

---
### **Story 1.4: 主数据融合与更新**
* **作为一个** 系统，
* **我想要** 在归档原始JSON后，自动执行一个“融合更新”算法，
* **以便** 智能地将新提取出的业务概念信息更新到`BusinessConceptsMaster`主数据表中，形成公司的权威画像。

* **验收标准:**
    1.  当处理一个新公司的第一份报告时，脚本能正确地在`Companies`表和`BusinessConceptsMaster`表中创建新条目。
    2.  当处理一个已有公司的新报告时，对于新出现的业务概念，能在主数据表中正确创建。
    3.  对于已存在的业务概念，能根据我们定义的融合规则（**覆盖**：`metrics`等时效性强的字段；**取并集**：`relations`等累积性强的字段）正确更新条目。
    4.  整个更新过程是事务性的，即要么全部成功，要么在失败时全部回滚，不产生中间状态的“脏数据”。

---
### **Story 1.5: 向量索引构建**
* **作为一个** 系统，
* **我想要** 在`BusinessConceptsMaster`表中的数据发生更新后，自动对新增或变更的业务概念进行向量化处理，
* **以便** 为后续的语义相似度搜索提供最新的索引。

* **验收标准:**
    1.  系统能自动识别出需要新建或更新向量索引的业务概念。
    2.  脚本能成功调用**本地部署的Qwen Embedding模型**，为每个业务概念的`concept_name`和`description`生成向量。
    3.  生成的向量能被成功写入对应业务概念在`BusinessConceptsMaster`表中的`pgvector`字段。
    4.  存入的向量维度与Qwen Embedding模型的输出维度完全一致。

---

## **Epic 2: MVP检索引擎与API构建**

* **史诗目标**: 在已有的数据基础上，构建一个功能完备的后端服务。该服务通过一个API接口，接收查询请求，执行核心的“向量检索 -> Rerank精排 -> 业务逻辑排序”流程，并返回最终的高度相关的公司列表。此阶段的产出是一个**可独立部署和测试的、功能完备的“智能大脑”**。

---
## **详细用户故事**

### **Story 2.1: 基础API接口搭建**
* **作为一个** 开发者，
* **我想要** 在`interfaces/api/`目录下，搭建起一个功能完备的FastAPI应用，包括路由、依赖注入和Pydantic 2.0的请求/响应模型（Schemas），
* **以便** 为我们的系统提供一个遵循“契约驱动”原则的、健壮的、标准化的外部交互入口。

* **验收标准 (Acceptance Criteria):**
    1.  一个基础的FastAPI应用已在`src/interfaces/api/`中创建并可以成功运行。
    2.  `POST /api/v1/search/similar-companies` 端点已在`src/interfaces/api/v1/routers/`中定义。
    3.  所有请求体和响应体的Pydantic模型（“契约”）已在`src/interfaces/api/v1/schemas/`中定义，并与《架构文档》v2.0第五部分中的API详细契约完全一致。
    4.  API能够使用Pydantic对请求体（`query_identifier`, `market_filters`等）进行严格的格式和类型验证。
    5.  对于无效的请求参数，能够返回符合HTTP规范的`422 Unprocessable Entity`错误响应。

---
### **Story 2.2: 核心向量检索逻辑实现**
* **作为一个** 系统，
* **我想要** 在收到API请求后，能够根据传入的公司简称或代码，执行并行的向量相似度检索，
* **以便** 快速、全面地从数据库中召回所有语义上相关的候选业务概念。

* **验收标准:**
    1.  系统能根据API传入的`query_identifier`（无论是简称还是代码），从`infrastructure/persistence/postgres/`实现的仓储中成功定位到目标公司。
    2.  系统能从`business_concepts_master`表中成功查询到该公司的所有业务概念。
    3.  系统能为该公司的每一个业务概念，都成功在`pgvector`索引中执行一次向量相似度查询。
    4.  所有概念的查询是并行执行的，以提高效率。
    5.  查询能够返回一个包含Top K个（例如K=50）候选`Document`对象的列表，作为下一步的输入。

---
### **Story 2.3: Rerank模型集成与精排**
* **作为一个** 系统，
* **我想要** 将向量检索召回的初步候选结果，输入到本地部署的Qwen Rerank模型中进行二次排序，
* **以便** 大幅提升最终结果头部的精准度，过滤掉语义上相关但实际上可能不匹配的结果。

* **验收标准:**
    1.  从Story 2.2中获得的候选`Document`列表被成功传递给`infrastructure/llm/qwen/`中实现的Rerank适配器。
    2.  Rerank模型能对候选列表进行有效的重排序，并为每个文档输出一个新的、更精准的相关性分数。
    3.  此步骤的输出是一个经过了二次排序和评分的、更高质量的`Document`列表。

---
### **Story 2.4: 核心排序算法实现**
* **作为一个** 系统，
* **我想要** 对经过Rerank模型精排后的结果，应用我们定义好的**核心排序算法**，
* **以便** 将我们的业务理解（如概念的重要性）融入到最终的排序中。

* **验收标准:**
    1.  `application/use_cases/search_similar_companies.py`中的用例，能够成功调用`domain/services/similarity_calculator.py`领域服务。
    2.  该领域服务能正确地应用加权公式 `RankingScore = w1 * RerankScore + w2 * SourceConcept_ImportanceScore`。
    3.  公式中的`RerankScore`是Story 2.3输出的新分数。
    4.  `SourceConcept_ImportanceScore`被正确地从查询公司的对应业务概念中获取。
    5.  每个候选概念都获得了一个最终的业务相关性分数。

---
### **Story 2.5: 结果聚合与最终输出**
* **作为一个** 系统，
* **我想要** 将所有经过排序的、独立的业务概念结果，按公司进行聚合，并应用行情过滤器，
* **以便** 向用户返回一个清晰的、按公司相关性排序的最终列表。

* **验收标准:**
    1.  所有独立的业务概念，被正确地按照其所属的`company_name`进行分组。
    2.  每个公司的最终总分，是其下所有匹配概念分数的合理聚合（例如，取最高分或加权平均）。
    3.  `market_filters`中的所有过滤条件（如市值、成交量）被正确应用在最终的公司列表上。
    4.  最终返回的JSON响应体，其结构与《架构文档》v2.0第五部分中定义的API详细契约完全一致。

---

## **Epic 3: 高级功能与优化**

* **史诗目标**: 在已有的检索引擎基础上，集成RAG质量评估、全链路监控和分布式缓存等高级功能，将系统从一个“功能完备的引擎”提升为一个**“可观测、可评估、高性能的生产级服务”**。

---
## **详细用户故事**

### **Story 3.1: RAG质量评估集成**
* **作为一个** 开发者，
* **我想要** 在`scripts/evaluation/`目录下，创建一个使用`RAGAS`框架的自动化评估脚本，
* **以便** 能够定期、量化地评估我们RAG管道的核心质量指标，为模型和提示词的持续迭代提供数据支持。

* **验收标准 (Acceptance Criteria):**
    1.  评估脚本可以成功加载一个预定义的“黄金标准”问答数据集（包含问题、基准答案、上下文等）。
    2.  脚本能够调用我们已有的检索链（`SearchSimilarCompaniesUseCase`），为数据集中的每个问题生成答案和上下文。
    3.  脚本能成功使用`RAGAS`计算出核心指标，至少包括`context_precision`（上下文精确率）和`faithfulness`（忠实度）。
    4.  评估结果能够以清晰的格式（如CSV或JSON）输出，便于分析。

---
### **Story 3.2: 分布式链路追踪集成**
* **作为一个** 开发者，
* **我想要** 在`infrastructure/monitoring/`和`interfaces/api/`模块中，集成`OpenTelemetry`，
* **以便** 为我们的API请求和后台数据处理任务，实现端到端的分布式链路追踪，从而极大地提升系统的可观测性和调试效率。

* **验收标准:**
    1.  FastAPI应用中已正确配置`OpenTelemetry`中间件。
    2.  每一个进入API的请求都会被分配一个唯一的`trace_id`。
    3.  这个`trace_id`能够在日志中跨越不同的服务和模块（例如，从`interfaces`层到`application`层再到`infrastructure`层）进行传递。
    4.  对于离线数据处理管道，每次运行也应生成一个唯一的追踪ID。
    5.  链路追踪数据可以被正确导出（例如，打印到控制台或发送到像Jaeger这样的后端）。

---
### **Story 3.3: 分布式缓存集成**
* **作为一个** 开发者，
* **我想要** 在`infrastructure/persistence/cache/`目录下，实现一个基于Redis的缓存适配器，并在`application`层的用例中集成缓存逻辑，
* **以便** 能够缓存高频的查询结果，显著降低API的平均响应时间并减少不必要的重复计算。

* **验收标准:**
    1.  一个连接到Redis的缓存适配器已在`infrastructure`层实现，并提供了`get`和`set`等标准接口。
    2.  `SearchSimilarCompaniesUseCase`在执行检索前，会先根据请求参数（如`query_identifier`, `filters`等）生成一个唯一的`cache_key`，并尝试从缓存中获取结果。
    3.  如果缓存命中，用例将直接返回缓存中的数据，不再执行后续的检索和排序。
    4.  如果缓存未命中，用例将执行完整的检索流程，并在返回最终结果前，将结果存入缓存，并设置合理的过期时间（例如，24小时）。

---
### **Story 3.4: 生产就绪与健康检查**
* **作为一个** 开发者，
* **我想要** 为我们的FastAPI应用添加一个`/health`健康检查端点，并完善CI/CD流程，
* **以便** 确保我们的服务是可监控的，并能够被自动化地、可靠地部署到生产环境。

* **验收标准:**
    1.  API中已实现`GET /health`端点，当服务正常时，它应返回`{"status": "ok"}`和`200`状态码。
    2.  健康检查应能验证与数据库等下游服务的连接是否正常。
    3.  GitHub Actions的CI/CD流水线已完成，能够自动运行所有测试、构建Docker镜像，并通过自托管运行器将其部署到预发布和生产环境。
    4.  部署脚本（`scripts/deployment/`）是幂等的，可以被安全地重复执行。

---
