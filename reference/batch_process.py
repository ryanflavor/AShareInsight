import os
import json
import glob
from concurrent.futures import ThreadPoolExecutor, as_completed
from gemini_analysis import load_prompt, call_gemini_api


def process_single_file(input_path):
    """Process a single markdown file and return the result"""
    try:
        # Read the document content
        with open(input_path, "r", encoding="utf-8") as f:
            document_content = f.read()

        # Load the prompt template
        prompt_template = load_prompt()

        # Extract company name from filename
        filename = os.path.basename(input_path)
        company_name = filename.replace("_2024å¹´å¹´åº¦æŠ¥å‘Šæ‘˜è¦.md", "")

        print(f"ğŸ“„ æ­£åœ¨å¤„ç†: {company_name}")

        # Call the API
        result = call_gemini_api(prompt_template, document_content)

        # Try to parse as JSON, removing markdown code blocks if present
        try:
            # Clean up response - remove markdown code blocks
            clean_result = result.strip()
            if clean_result.startswith("```json"):
                clean_result = clean_result[7:]  # Remove ```json
            if clean_result.endswith("```"):
                clean_result = clean_result[:-3]  # Remove ```
            clean_result = clean_result.strip()

            parsed_result = json.loads(clean_result)
            print(f"âœ… {company_name} - åˆ†æå®Œæˆ")
            return {
                "company": company_name,
                "input_file": input_path,
                "success": True,
                "data": parsed_result,
            }
        except json.JSONDecodeError as e:
            print(f"âŒ {company_name} - JSONè§£æå¤±è´¥: {e}")
            return {
                "company": company_name,
                "input_file": input_path,
                "success": False,
                "raw_response": result,
                "error": f"JSONè§£æå¤±è´¥: {e}",
            }

    except Exception as e:
        print(f"âŒ {company_name} - å¤„ç†å¤±è´¥: {e}")
        return {
            "company": company_name,
            "input_file": input_path,
            "success": False,
            "error": str(e),
        }


def main():
    """Main batch processing function"""
    # Find all markdown files in inputs directory
    input_files = glob.glob("inputs/*.md")

    if not input_files:
        print("âŒ åœ¨inputsç›®å½•ä¸­æœªæ‰¾åˆ°.mdæ–‡ä»¶")
        return

    print(f"ğŸ” å‘ç° {len(input_files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")

    # Create outputs directory if it doesn't exist
    os.makedirs("outputs", exist_ok=True)

    # Process files concurrently
    results = []
    with ThreadPoolExecutor(max_workers=3) as executor:
        # Submit all tasks
        future_to_file = {
            executor.submit(process_single_file, file_path): file_path
            for file_path in input_files
        }

        # Collect results as they complete
        for future in as_completed(future_to_file):
            result = future.result()
            results.append(result)

            # Save individual result
            if result["success"]:
                output_file = f"outputs/{result['company']}_analysis.json"
                with open(output_file, "w", encoding="utf-8") as f:
                    json.dump(result["data"], f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ å·²ä¿å­˜: {output_file}")
            else:
                # Save error log
                error_file = f"outputs/{result['company']}_error.json"
                with open(error_file, "w", encoding="utf-8") as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"âš ï¸  é”™è¯¯æ—¥å¿—: {error_file}")

    # Summary report
    successful = len([r for r in results if r["success"]])
    failed = len(results) - successful

    print("\nğŸ“Š å¤„ç†å®Œæˆ:")
    print(f"   âœ… æˆåŠŸ: {successful} ä¸ªæ–‡ä»¶")
    print(f"   âŒ å¤±è´¥: {failed} ä¸ªæ–‡ä»¶")

    # Save summary
    summary = {
        "total_files": len(input_files),
        "successful": successful,
        "failed": failed,
        "results": results,
    }

    with open("outputs/batch_summary.json", "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    print("ğŸ“‹ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: outputs/batch_summary.json")


if __name__ == "__main__":
    main()
